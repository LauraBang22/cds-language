{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Extracting linguistic features using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we install and import the relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we download a particular model from spaCy to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loop over each text file in the folder called \"in\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with all the texts in the folder called \"in\", then we have to create a \"for loop\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = (\"../in/USEcorpus\") #the folder that we will be working in\n",
    "sorted_dir = sorted(os.listdir(main_folder_path)) #sorting all the subfolders\n",
    "\n",
    "for folder in sorted_dir: #creating a \"for loop\" to reach all the subfolders\n",
    "    folder_path = os.path.join(main_folder_path, folder) \n",
    "    filenames = sorted(os.listdir(folder_path)) #sorting all the files in the different subfolders\n",
    "    for filename in filenames: #creating a new \"for loop\" to reach all the files in the subfolders\n",
    "        filepath = folder_path + \"/\" + filename\n",
    "        with open(filepath, encoding=\"latin-1\") as f: \n",
    "            text = f.read() #opening all the files in one text\n",
    "        doc = nlp(text) #creating a \"doc\" of all the files\n",
    "        noun_count = 0\n",
    "        verb_count = 0\n",
    "        adj_count = 0\n",
    "        adv_count = 0\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"NOUN\":\n",
    "                noun_count += 1\n",
    "            elif token.pos_ == \"VERB\":\n",
    "                verb_count += 1\n",
    "            elif token.pos_ == \"ADJ\":\n",
    "                adj_count += 1\n",
    "            elif token.pos_ == \"ADV\":\n",
    "                adv_count += 1\n",
    "        relative_freq_noun = (noun_count/len(doc)) * 10000\n",
    "        relative_freq_verb = (verb_count/len(doc)) * 10000\n",
    "        relative_freq_adj = (adj_count/len(doc)) * 10000\n",
    "        relative_freq_adv = (adv_count/len(doc)) * 10000\n",
    "        persons = set() #First create a new set\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'PERSON': #Find all the entities in the doc that has the label PERSON\n",
    "                persons.add(ent.text) #Then add them to the set cwe created\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0502.c1.txt 208 197 61 90\n"
     ]
    }
   ],
   "source": [
    "print(filename, noun_count, verb_count, adj_count, adv_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract the following information:\n",
    "- Relative frequency of Nouns, Verbs, Adjective, and Adverbs per 10,000 words\n",
    "- Total number of unique PER, LOC, ORGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define four variables, where the count of the different POS are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_count = 0\n",
    "verb_count = 0\n",
    "adj_count = 0\n",
    "adv_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a \"for loop\", where for each token of the specific POS, then it'll and one to the counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        noun_count += 1\n",
    "    elif token.pos_ == \"VERB\":\n",
    "        verb_count += 1\n",
    "    elif token.pos_ == \"ADJ\":\n",
    "        adj_count += 1\n",
    "    elif token.pos_ == \"ADV\":\n",
    "        adv_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can run the different count variables, and find out how many there are in the text of each POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we try to find the relative frequency of each of the POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1311.79"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_noun = (noun_count/len(doc)) * 10000\n",
    "\n",
    "round(relative_freq_noun, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1210.39"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_verb = (verb_count/len(doc)) * 10000\n",
    "\n",
    "round(relative_freq_verb, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430.93"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_adj = (adj_count/len(doc)) * 10000\n",
    "\n",
    "round(relative_freq_adj, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405.58"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_adv = (adv_count/len(doc)) * 10000\n",
    "\n",
    "round(relative_freq_adv, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to find out how many unique PERSON, ORG and LOC there is in the texts.\n",
    "\n",
    "We'll start with unique number of PERSONs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "persons = set() #First create a new set\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PERSON': #Find all the entities in the doc that has the label PERSON\n",
    "        persons.add(ent.text) #Then add them to the set cwe created\n",
    "\n",
    "num_persons = len(persons) #This is how we find out how many unique PERSON the previous code has found\n",
    "\n",
    "print(num_persons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then repeat for ORG and LOC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "organisations = set()\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'ORG':\n",
    "        organisations.add(ent.text)\n",
    "\n",
    "num_organisations = len(organisations)\n",
    "\n",
    "print(num_organisations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "locations = set()\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'LOC':\n",
    "        locations.add(ent.text)\n",
    "\n",
    "num_locations = len(locations)\n",
    "\n",
    "print(num_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each sub-folder (a1, a2, a3, ...) save a table which shows the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for token in doc:\n",
    "    annotations.append((token.text, token.pos_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
