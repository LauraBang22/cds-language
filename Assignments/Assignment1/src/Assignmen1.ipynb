{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Extracting linguistic features using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we install and import the relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we download a particular model from spaCy to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with all the texts in the folder called \"in\", then we have to create a \"for loop\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loop over each text file in the folder called in\n",
    "\n",
    "main_folder_path = (\"../in/USEcorpus\") #the folder that we will be working in\n",
    "sorted_dir = sorted(os.listdir(main_folder_path)) #sorting all the subfolders\n",
    "\n",
    "for folder in sorted_dir: #creating a \"for loop\" to reach all the subfolders\n",
    "    folder_path = os.path.join(main_folder_path, folder) \n",
    "    filenames = sorted(os.listdir(folder_path)) #sorting all the files in the different subfolders\n",
    "    folder_info = [] #Define a empty list for later use\n",
    "    \n",
    "    for filename in filenames: #creating a new \"for loop\" to reach all the files in the subfolders\n",
    "        filepath = folder_path + \"/\" + filename\n",
    "        \n",
    "        with open(filepath, encoding=\"latin-1\") as f: \n",
    "            text = f.read() #opening all the files in one text\n",
    "            \n",
    "        doc = nlp(text) #creating a \"doc\" of all the files\n",
    "        \n",
    "        #2.1 Extract relative frequency of Nouns, Verbs, Adjective, and Adverbs per 10,000 words\n",
    "        \n",
    "        #First we define four variables, where the count of the different POS are 0        \n",
    "        noun_count = 0\n",
    "        verb_count = 0\n",
    "        adj_count = 0\n",
    "        adv_count = 0\n",
    "        \n",
    "        #Then we create a \"for loop\", where for each token of the specific POS, then it'll and one to the counter.        \n",
    "        for token in doc:\n",
    "            if token.pos_ == \"NOUN\":\n",
    "                noun_count += 1\n",
    "            elif token.pos_ == \"VERB\":\n",
    "                verb_count += 1\n",
    "            elif token.pos_ == \"ADJ\":\n",
    "                adj_count += 1\n",
    "            elif token.pos_ == \"ADV\":\n",
    "                adv_count += 1\n",
    "                \n",
    "        #Then we try to find the relative frequency of each of the POS\n",
    "        relative_freq_noun = (noun_count/len(doc)) * 10000\n",
    "        relative_freq_verb = (verb_count/len(doc)) * 10000\n",
    "        relative_freq_adj = (adj_count/len(doc)) * 10000\n",
    "        relative_freq_adv = (adv_count/len(doc)) * 10000\n",
    "        \n",
    "        #2.2 Extract total number of unique PER, LOC, ORGS\n",
    "        \n",
    "        persons = set() #First create a new set\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'PERSON': #Find all the entities in the doc that has the label PERSON\n",
    "                persons.add(ent.text) #Then add them to the set cwe created\n",
    "        num_persons = len(persons) #This is how we find out how many unique PERSON the previous code has found\n",
    "        \n",
    "        organisations = set()\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'ORG':\n",
    "                organisations.add(ent.text)\n",
    "        num_organisations = len(organisations)\n",
    "        \n",
    "        locations = set()\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'LOC':\n",
    "                locations.add(ent.text)\n",
    "        num_locations = len(locations)\n",
    "        \n",
    "        # 3. For each sub-folder (a1, a2, a3, ...) save a table which shows the information                \n",
    "        file_info = [filename, relative_freq_noun, relative_freq_verb, relative_freq_adj, relative_freq_adv, \n",
    "                     num_persons, num_organisations, num_locations] #\n",
    "        \n",
    "        folder_info.append(file_info)\n",
    "        \n",
    "        df = pd.DataFrame(folder_info, \n",
    "                         columns=[\"Filename\", \"RelFreq NOUN\", \"RelFreq VERB\", \"RelFreq ADJ\", \"RelFreq ADV\", \n",
    "                                  \"Unique PER\", \"Unique LOC\", \"Unique ORG\"])\n",
    "        \n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>RelFreq NOUN</th>\n",
       "      <th>RelFreq VERB</th>\n",
       "      <th>RelFreq ADJ</th>\n",
       "      <th>RelFreq ADV</th>\n",
       "      <th>Unique PER</th>\n",
       "      <th>Unique LOC</th>\n",
       "      <th>Unique ORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0140.c1.txt</td>\n",
       "      <td>1582.150101</td>\n",
       "      <td>920.892495</td>\n",
       "      <td>474.645030</td>\n",
       "      <td>434.077079</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0165.c1.txt</td>\n",
       "      <td>1721.212121</td>\n",
       "      <td>783.838384</td>\n",
       "      <td>589.898990</td>\n",
       "      <td>307.070707</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0200.c1.txt</td>\n",
       "      <td>1110.555278</td>\n",
       "      <td>1010.505253</td>\n",
       "      <td>615.307654</td>\n",
       "      <td>600.300150</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0219.c1.txt</td>\n",
       "      <td>1355.263158</td>\n",
       "      <td>1013.157895</td>\n",
       "      <td>532.894737</td>\n",
       "      <td>605.263158</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0238.c1.txt</td>\n",
       "      <td>1105.955143</td>\n",
       "      <td>1067.285383</td>\n",
       "      <td>386.697602</td>\n",
       "      <td>409.899459</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0501.c1.txt</td>\n",
       "      <td>1208.191126</td>\n",
       "      <td>1010.238908</td>\n",
       "      <td>457.337884</td>\n",
       "      <td>525.597270</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0502.c1.txt</td>\n",
       "      <td>1318.124208</td>\n",
       "      <td>1248.415716</td>\n",
       "      <td>386.565272</td>\n",
       "      <td>570.342205</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Filename  RelFreq NOUN  RelFreq VERB  RelFreq ADJ  RelFreq ADV  \\\n",
       "0  0140.c1.txt   1582.150101    920.892495   474.645030   434.077079   \n",
       "1  0165.c1.txt   1721.212121    783.838384   589.898990   307.070707   \n",
       "2  0200.c1.txt   1110.555278   1010.505253   615.307654   600.300150   \n",
       "3  0219.c1.txt   1355.263158   1013.157895   532.894737   605.263158   \n",
       "4  0238.c1.txt   1105.955143   1067.285383   386.697602   409.899459   \n",
       "5  0501.c1.txt   1208.191126   1010.238908   457.337884   525.597270   \n",
       "6  0502.c1.txt   1318.124208   1248.415716   386.565272   570.342205   \n",
       "\n",
       "   Unique PER  Unique LOC  Unique ORG  \n",
       "0          39           7           0  \n",
       "1          29           7           1  \n",
       "2          23           3           1  \n",
       "3          28           6           0  \n",
       "4          19           3           0  \n",
       "5          19           5           2  \n",
       "6          17           3           3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract the following information:\n",
    "- Relative frequency of Nouns, Verbs, Adjective, and Adverbs per 10,000 words\n",
    "- Total number of unique PER, LOC, ORGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define four variables, where the count of the different POS are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_count = 0\n",
    "verb_count = 0\n",
    "adj_count = 0\n",
    "adv_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a \"for loop\", where for each token of the specific POS, then it'll and one to the counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        noun_count += 1\n",
    "    elif token.pos_ == \"VERB\":\n",
    "        verb_count += 1\n",
    "    elif token.pos_ == \"ADJ\":\n",
    "        adj_count += 1\n",
    "    elif token.pos_ == \"ADV\":\n",
    "        adv_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can run the different count variables, and find out how many there are in the text of each POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we try to find the relative frequency of each of the POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1311.79"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_noun = (noun_count/len(doc)) * 10000\n",
    "\n",
    "round(relative_freq_noun, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1210.39"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_verb = (verb_count/len(doc)) * 10000\n",
    "\n",
    "round(relative_freq_verb, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430.93"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_adj = (adj_count/len(doc)) * 10000\n",
    "\n",
    "round(relative_freq_adj, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405.58"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_adv = (adv_count/len(doc)) * 10000\n",
    "\n",
    "round(relative_freq_adv, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to find out how many unique PERSON, ORG and LOC there is in the texts.\n",
    "\n",
    "We'll start with unique number of PERSONs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "persons = set() #First create a new set\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PERSON': #Find all the entities in the doc that has the label PERSON\n",
    "        persons.add(ent.text) #Then add them to the set cwe created\n",
    "\n",
    "num_persons = len(persons) #This is how we find out how many unique PERSON the previous code has found\n",
    "\n",
    "print(num_persons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then repeat for ORG and LOC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "organisations = set()\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'ORG':\n",
    "        organisations.add(ent.text)\n",
    "\n",
    "num_organisations = len(organisations)\n",
    "\n",
    "print(num_organisations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "locations = set()\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'LOC':\n",
    "        locations.add(ent.text)\n",
    "\n",
    "num_locations = len(locations)\n",
    "\n",
    "print(num_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each sub-folder (a1, a2, a3, ...) save a table which shows the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for token in doc:\n",
    "    annotations.append((token.text, token.pos_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
